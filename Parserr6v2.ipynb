{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a86844",
   "metadata": {},
   "source": [
    "# Put this Jupyter Notebook(code) in the same file as the input csv\n",
    "# Change the settings below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a9fc985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from typing import Any, Dict, List, Tuple, Callable\n",
    "\n",
    "# Edit these rach runn\n",
    "SCHEMA_CSV      = \"887_Schema_mp_cs.dim_survey_df__sg_cx_view_20250916-134323.csv\"\n",
    "SUBMISSIONS_CSV = \"887_Submissions_mp_cs.dwd_survey_submission_di__sg_cx_view_20250924-155511.csv\"\n",
    "OUT_CSV         = \"887_survey_parsed.csv\"\n",
    "\n",
    "# column names inside your files (check this before running)\n",
    "SCHEMA_COL     = \"survey_schema\"\n",
    "RESP_JSON_COL  = \"submitted_data\"\n",
    "ID_COL         = \"response_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c290c",
   "metadata": {},
   "source": [
    "- Note that: Emojis cannot be processed and will be output in their encoding format, in the output csv. \n",
    "- Some columns are redundant, but is created due to the safeguard of the code, which is to detect all possible questions. Kindly clean the output csv file up by deleting unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60b65877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: 887_survey_parsed.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- helpers ----------\n",
    "def walk_schema(schema: Dict[str, Any]) -> List[Tuple[str, Dict[str, Any]]]:\n",
    "    out: List[Tuple[str, Dict[str, Any]]] = []\n",
    "    def walk(n: Any) -> None:\n",
    "        if isinstance(n, dict) and n.get(\"type\") == \"object\" and isinstance(n.get(\"properties\"), dict):\n",
    "            # within \"properties\", is a nested dictionary of qn code(key), qn object(value)\n",
    "            for qcode, child in n[\"properties\"].items(): #qcode is the object code, then child is the dict\n",
    "                if isinstance(child, dict):\n",
    "                    out.append((qcode, child)) #grab the question/object code and return the child\n",
    "                    walk(child)\n",
    "    walk(schema)\n",
    "    return out\n",
    "\n",
    "def classify_kind(node: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    One of: 'ranking', 'multiselect', 'single_select', 'rating', 'single_text'.\n",
    "    \"\"\"\n",
    "    t = node.get(\"type\")\n",
    "    title = (node.get(\"title\") or node.get(\"questionLabel\") or \"\")\n",
    "    title_lc = title.lower() if isinstance(title, str) else \"\"\n",
    "    has_options = isinstance(node.get(\"options\"), list) and len(node[\"options\"]) > 0\n",
    "    has_score_marks = isinstance(node.get(\"scoreMarks\"), list) and len(node[\"scoreMarks\"]) >= 2\n",
    "\n",
    "    if has_score_marks:\n",
    "        return \"rating\"\n",
    "    if has_options and (\"rank\" in title_lc or \"preference\" in title_lc):\n",
    "        return \"ranking\"\n",
    "    if has_options:\n",
    "        return \"single_select\"\n",
    "    if t == \"string\":\n",
    "        return \"single_text\"\n",
    "    return \"single_text\"\n",
    "\n",
    "def build_specs(schema: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    specs: List[Dict[str, Any]] = []\n",
    "    for code, node in walk_schema(schema):\n",
    "        title_raw = node.get(\"title\") or node.get(\"questionLabel\") or \"\"\n",
    "        title = title_raw.strip() if isinstance(title_raw, str) else str(title_raw)\n",
    "        kind = classify_kind(node)\n",
    "        specs.append({\"code\": code, \"title\": title, \"kind\": kind})\n",
    "    return specs #specs is a list of dictionaries, \"code\":\"af94dcb2e4\", \"title\":\"Description Area\",  \"kind\" :\"rating\"\n",
    "\n",
    "def make_title_columns_only(specs: List[Dict[str, Any]]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Map question code -> unique title (titles only; no codes).\n",
    "    If duplicates appear, append ' (2)', ' (3)', ...\n",
    "    Blank titles become 'no title'.\n",
    "    \"\"\"\n",
    "    used_counts: Dict[str, int] = {}\n",
    "    m: Dict[str, str] = {}\n",
    "    for s in specs:\n",
    "        base = s[\"title\"].strip() if isinstance(s[\"title\"], str) else \"\"\n",
    "        if not base:\n",
    "            base = \"no title\"\n",
    "        used_counts[base] = used_counts.get(base, 0) + 1\n",
    "        name = base if used_counts[base] == 1 else f\"{base} ({used_counts[base]})\"\n",
    "        m[s[\"code\"]] = name\n",
    "    return m\n",
    "\n",
    "# helper: get all schema nodes by code (so we can read options for ranking size)\n",
    "def nodes_by_code(schema: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:\n",
    "    return {code: node for code, node in walk_schema(schema)}\n",
    "\n",
    "# ---------- extractors for non-ranking questions ----------\n",
    "def ext_single_text(v: Any) -> str:\n",
    "    if isinstance(v, dict):\n",
    "        if v.get(\"label\") is not None: return str(v[\"label\"])\n",
    "        if v.get(\"value\") is not None and not isinstance(v[\"value\"], (dict, list)): return str(v[\"value\"])\n",
    "        return \"\"\n",
    "    if isinstance(v, (str, int, float)): return str(v)\n",
    "    return \"\"\n",
    "\n",
    "def ext_single_select(v: Any) -> str:\n",
    "    if isinstance(v, dict) and v.get(\"label\") is not None: return str(v[\"label\"])\n",
    "    if isinstance(v, (str, int, float)): return str(v)\n",
    "    return \"\"\n",
    "\n",
    "def ext_multiselect(v: Any) -> str:\n",
    "    # Accept list of dicts (with 'label'), list of strings, or a single dict\n",
    "    if isinstance(v, list):\n",
    "        pairs: List[Tuple[str,str]] = []\n",
    "        for it in v:\n",
    "            if isinstance(it, dict):\n",
    "                lab = it.get(\"label\")\n",
    "                val =it.get(\"value\")\n",
    "                if lab is not None and val is not None:\n",
    "                    pairs.append((str(lab).strip(), str(val).strip()))\n",
    "           \n",
    "    return \";\".join( f\"{lab}({val})\" for lab, val in pairs )\n",
    "    \n",
    "\n",
    "def ms_labels_and_other(v: Any) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Returns (labels_joined, other_text).\n",
    "    - labels_joined: '; '.join of non-'other' labels\n",
    "    - other_text: free text from the 'other' option (value), or '' if not present\n",
    "    \"\"\"\n",
    "    labels: List[str] = []\n",
    "    other_text = \"\"\n",
    "\n",
    "    if isinstance(v, list):\n",
    "        for it in v:\n",
    "            if not isinstance(it, dict):\n",
    "                if it is not None:\n",
    "                    labels.append(str(it).strip())\n",
    "                continue\n",
    "\n",
    "            lab = (it.get(\"label\") or \"\").strip()\n",
    "            val = it.get(\"value\")\n",
    "            is_other = (\n",
    "                bool(it.get(\"isOther\")) or\n",
    "                str(it.get(\"key\", \"\")).lower() == \"isother\" or\n",
    "                \"other\" in lab.lower()\n",
    "            )\n",
    "\n",
    "            if is_other:\n",
    "                # take free text from 'value' if present\n",
    "                labels.append(lab if lab else \"other\")\n",
    "                if isinstance(val, (str, int, float)):\n",
    "                    if not other_text:\n",
    "                        other_text = str(val).strip()\n",
    "            else:\n",
    "                if lab:\n",
    "                    labels.append(lab)\n",
    "\n",
    "    return \"; \".join(labels), other_text\n",
    "\n",
    "\n",
    "def ext_rating(v: Any) -> str:\n",
    "    if isinstance(v, (int, float)):\n",
    "        return str(int(v)) if isinstance(v, float) and v.is_integer() else str(v)\n",
    "    if isinstance(v, dict) and isinstance(v.get(\"value\"), (int, float)):\n",
    "        val = v[\"value\"]\n",
    "        return str(int(val)) if isinstance(val, float) and val.is_integer() else str(val)\n",
    "    return \"\"\n",
    "\n",
    "EXTRACTORS: Dict[str, Callable[[Any], str]] = {\n",
    "    \"single_text\":   ext_single_text,\n",
    "    \"single_select\": ext_single_select,\n",
    "    \"multiselect\":   ext_multiselect,\n",
    "    \"rating\":        ext_rating,\n",
    "}\n",
    "\n",
    "# infer ranking length from responses if schema options are absent\n",
    "def infer_rank_len_from_responses(resp_df: pd.DataFrame, rank_code: str) -> int:\n",
    "    max_len = 0\n",
    "    for raw in resp_df[RESP_JSON_COL].tolist():\n",
    "        try:\n",
    "            payload = json.loads(raw) if isinstance(raw, str) else (raw or {})\n",
    "        except Exception:\n",
    "            payload = {}\n",
    "        v = payload.get(rank_code)\n",
    "        if isinstance(v, list):\n",
    "            max_len = max(max_len, len(v))\n",
    "    return max_len\n",
    "\n",
    "# ---------- run ----------\n",
    "# 1) read CSVs\n",
    "schema_df = pd.read_csv(SCHEMA_CSV, low_memory=False, encoding=\"utf-8\")\n",
    "resp_df   = pd.read_csv(SUBMISSIONS_CSV, low_memory=False, encoding =\"utf-8\")\n",
    "\n",
    "# 2) parse schema JSON\n",
    "schema = json.loads(schema_df[SCHEMA_COL].iloc[0])\n",
    "\n",
    "# 3) build specs + columns (titles only) + node lookup\n",
    "specs = build_specs(schema)\n",
    "code_to_col = make_title_columns_only(specs)\n",
    "kind_by_code = {s[\"code\"]: s[\"kind\"] for s in specs}\n",
    "node_map = nodes_by_code(schema)\n",
    "\n",
    "# 3b) pre-compute ranking column expansions per ranking question\n",
    "ranking_codes = [s[\"code\"] for s in specs if s[\"kind\"] == \"ranking\"]\n",
    "rank_cols_by_code: Dict[str, List[str]] = {}\n",
    "rank_len_by_code: Dict[str, int] = {}\n",
    "\n",
    "for code in ranking_codes:\n",
    "    node = node_map.get(code, {})\n",
    "    # prefer schema options length\n",
    "    n = len(node.get(\"options\", [])) if isinstance(node.get(\"options\"), list) else 0\n",
    "    # if missing, infer from responses\n",
    "    if n == 0:\n",
    "        n = infer_rank_len_from_responses(resp_df, code)\n",
    "    rank_len_by_code[code] = n\n",
    "    base_title = code_to_col[code]  # unique title for this question\n",
    "    rank_cols_by_code[code] = [f\"{base_title} [{i}]\" for i in range(1, n + 1)]\n",
    "\n",
    "# 4) transform each submission row\n",
    "rows: List[Dict[str, Any]] = []\n",
    "other_cols_by_code: Dict[str, str] = {}  # code -> \"<title> - Other\"\n",
    "\n",
    "for _, row in resp_df.iterrows(): #iterrows is pandas method to get _,row which is (index, series) pairs\n",
    "    raw = row.get(RESP_JSON_COL) # a row is a pandas series respresenting the whole row, represented in a dictionary format. We get the submitted_data column here\n",
    "    try:\n",
    "        payload = json.loads(raw) if isinstance(raw, str) else (raw or {}) #sort of like if-else, but try, except is for error handling, while if else is for branching.\n",
    "    except json.JSONDecodeError: #if json throws this error, set the payload into blank\n",
    "        payload = {}\n",
    "\n",
    "    rec: Dict[str, Any] = {} #for each row, acts as dictionary of metadata, then the column header if matches will call up this dictionary and output the value.\n",
    "    if ID_COL in resp_df.columns: #ID_COL is response id\n",
    "        rec[ID_COL] = row[ID_COL] #each iteration == each row, check response id for that row and create dict entry(response_id, actual number)\n",
    "        rec[\"user_id\"] = row[\"user_id\"]\n",
    "        rec[\"response_submitted_date\"] = row[\"response_submitted_date\"]\n",
    " \n",
    "    # initialize all ranking position columns as blank\n",
    "    for code in ranking_codes:\n",
    "        for colname in rank_cols_by_code[code]:\n",
    "            rec[colname] = \"\"\n",
    "\n",
    "    # fill values\n",
    "    for s in specs:\n",
    "        code = s[\"code\"]\n",
    "        v    = payload.get(code)\n",
    "\n",
    "        if s[\"kind\"] == \"ranking\":\n",
    "            # fill position columns instead of a single aggregated cell\n",
    "            labels = []\n",
    "            if isinstance(v, list):\n",
    "                for item in v:\n",
    "                    if isinstance(item, dict) and item.get(\"label\") is not None:\n",
    "                        labels.append(str(item[\"label\"]))\n",
    "                    elif item is not None:\n",
    "                        labels.append(str(item))\n",
    "            # write into [1]..[N]\n",
    "            cols_for_this = rank_cols_by_code.get(code, [])\n",
    "            n = len(cols_for_this)\n",
    "            for i in range(n):\n",
    "                rec[cols_for_this[i]] = labels[i] if i < len(labels) else \"\"\n",
    "        else:\n",
    "            colname = code_to_col[code]\n",
    "\n",
    "            if isinstance(v, list):\n",
    "                # Treat lists as multiselect and split out 'Other'\n",
    "                labels_joined, other_text = ms_labels_and_other(v)\n",
    "                rec[colname] = labels_joined\n",
    "\n",
    "                if other_text != \"\":\n",
    "                    other_col = f\"{colname} - Other\"\n",
    "                    rec[other_col] = other_text\n",
    "                    other_cols_by_code.setdefault(code, other_col)\n",
    "\n",
    "            elif kind_by_code.get(code) == \"rating\":\n",
    "                rec[colname] = EXTRACTORS[\"rating\"](v)\n",
    "\n",
    "            else:\n",
    "                runtime_kind = kind_by_code.get(code, \"single_text\")\n",
    "                rec[colname] = EXTRACTORS.get(runtime_kind, ext_single_text)(v)\n",
    "\n",
    "\n",
    "\n",
    "    rows.append(rec)\n",
    "\n",
    "# 5) assemble + save (order: id, then for each spec either its ranking subcolumns or the single column)\n",
    "out_df = pd.DataFrame.from_records(rows) # from_records makes a DataFrame from a list of rows dict, where one dict = one row of entry. DIct keys become columns, each dict become 1 row.\n",
    "\n",
    "ordered_cols: List[str] = []\n",
    "if ID_COL in out_df.columns: ordered_cols.append(ID_COL)\n",
    "if \"user_id\" in out_df.columns: ordered_cols.append(\"user_id\")\n",
    "if \"response_submitted_date\" in out_df.columns: ordered_cols.append(\"response_submitted_date\")\n",
    "\n",
    "for s in specs:\n",
    "    if s[\"kind\"] == \"ranking\":\n",
    "        ordered_cols.extend(rank_cols_by_code.get(s[\"code\"], []))\n",
    "    else:\n",
    "        main_col = code_to_col[s[\"code\"]]\n",
    "        ordered_cols.append(main_col)\n",
    "        # add companion 'Other' column if we created it\n",
    "        oc = other_cols_by_code.get(s[\"code\"])\n",
    "        if oc:\n",
    "            ordered_cols.append(oc)\n",
    "\n",
    "\n",
    "out_df = out_df.reindex(columns=ordered_cols)\n",
    "out_df.to_csv(OUT_CSV, index=False, encoding =\"utf-8-sig\")\n",
    "print(f\"Wrote: {OUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
